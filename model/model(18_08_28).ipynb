{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Documents\\Deep_learning\\future_lab\\lab_project02\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "cwd = os.getcwd()\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,Softmax,Input,Flatten\n",
    "from keras.optimizers import Adam,RMSprop,SGD\n",
    "from keras.layers.merge import add\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from IPython.display import display\n",
    "from  PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kapre.utils import Normalization2D\n",
    "from kapre.augmentation import AdditiveNoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 720, 288\n",
    "# img_width, img_height = 150, 150 # VGG 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = cwd + '/img_data'\n",
    "# validation_data_dir = cwd + '/chest_xray/val'\n",
    "# test_data_dir = cwd + '/chest_xray/test'\n",
    "\n",
    "# nb_train_samples = 5217\n",
    "# nb_validation_samples = 17\n",
    "epochs = 20\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7997 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(AdditiveNoise(power=0.2))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\",\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20,activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy']) # if single-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 720, 288, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 720, 288, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 720, 288, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 360, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 360, 144, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 360, 144, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 360, 144, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 360, 144, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 180, 72, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 180, 72, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 829440)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                16588820  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 168       \n",
      "=================================================================\n",
      "Total params: 16,655,020\n",
      "Trainable params: 16,654,788\n",
      "Non-trainable params: 232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = ModelCheckpoint(\"test_audio_model.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "tb = TensorBoard(log_dir='test_tl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 761s 381ms/step - loss: 2.0613 - acc: 0.1933\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 764s 382ms/step - loss: 1.9772 - acc: 0.2141\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 764s 382ms/step - loss: 1.9420 - acc: 0.2280\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 761s 380ms/step - loss: 1.9201 - acc: 0.2590\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 763s 381ms/step - loss: 1.8948 - acc: 0.2750\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 762s 381ms/step - loss: 1.8635 - acc: 0.2880\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 763s 382ms/step - loss: 1.8206 - acc: 0.3041\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 762s 381ms/step - loss: 1.8149 - acc: 0.3145\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 764s 382ms/step - loss: 1.7917 - acc: 0.3278\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 762s 381ms/step - loss: 1.7534 - acc: 0.3378\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 772s 386ms/step - loss: 1.7143 - acc: 0.3560\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 771s 386ms/step - loss: 1.6771 - acc: 0.3751\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 773s 386ms/step - loss: 1.6403 - acc: 0.3850\n",
      "Epoch 14/20\n",
      "2000/2000 [==============================] - 774s 387ms/step - loss: 1.6096 - acc: 0.3991\n",
      "Epoch 15/20\n",
      "2000/2000 [==============================] - 779s 389ms/step - loss: 1.5809 - acc: 0.4059\n",
      "Epoch 16/20\n",
      "2000/2000 [==============================] - 777s 388ms/step - loss: 1.5465 - acc: 0.4169\n",
      "Epoch 17/20\n",
      "2000/2000 [==============================] - 776s 388ms/step - loss: 1.4978 - acc: 0.4375\n",
      "Epoch 18/20\n",
      "2000/2000 [==============================] - 777s 388ms/step - loss: 1.4656 - acc: 0.4535\n",
      "Epoch 19/20\n",
      "2000/2000 [==============================] - 777s 389ms/step - loss: 1.4594 - acc: 0.4506\n",
      "Epoch 20/20\n",
      "2000/2000 [==============================] - 778s 389ms/step - loss: 1.4097 - acc: 0.4615\n"
     ]
    }
   ],
   "source": [
    "with K.tf.device('/gpu:0'):\n",
    "    hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs = epochs,\n",
    "        callbacks = [tb]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7e08bac5a9ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0macc_ax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwinx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mloss_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0macc_ax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADoRJREFUeJzt3FGInWedx/Hvz8asdKy6bBAkibbL\npmAoC7qhdm9WXXVJe5HciCQgbqUYcKkLqwgFL5R6tcoiCEWdZaWroDV6oUGULLgVRYwk2LWYlMhs\nFDtUqKu1F5PVOrv/vZiTndPpzP+8seedadPvBw6c97xPnuc5D2f+v7zve96TqkKSpK28aKcnIEl6\nbjMoJEktg0KS1DIoJEktg0KS1DIoJEmtmUGR5LNJHk/y4y32J8knkywleTjJ6+c/TUnSEGPU7CFH\nFPcDh5v9twMHJo8TwKcG9ClJGsf9zLlmzwyKqvoO8OumyVHgc7XmDPCKJK+a1a8kaf7GqNm75jCv\nvcCjU9vLk9d+sbFhkhOsJRjAX1x//fVzGF6SXjguX75cwA+nXlqsqsWr6GJwzb5iHkGRTV7b9HdB\nJm9mEWBhYaFWVlbmMLwkvXAk+e+qOvRsutjktfa3nObxradlYP/U9j7gsTn0K0mav6uu2fMIilPA\nuyZX0m8DnqyqLQ9hJEk76qpr9sxTT0m+CLwJ2JNkGfgw8GKAqvo08A3gDmAJuAy8+9m8A0nSH26M\nmp2d+plxr1FI0tVLcrmqFrZzTO/MliS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsug\nkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1\nDApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJ\nUsugkCS1BgVFksNJLiZZSnLPJvtfneTBJA8leTjJHfOfqiRpljHqdapq1qDXAT8B3gYsA2eB41V1\nYarNIvBQVX0qyUHgG1V1Y9fvwsJCrayszJqfJGlKkstVtbDFvlHq9ZAjiluBpaq6VFVPAQ8ARze0\nKeBlk+cvBx4b0K8kab5Gqde7Bgy8F3h0ansZeMOGNh8B/i3J+4AF4K2bdZTkBHACYPfu3QOGliRt\nsCvJuantxapanDyfW72eNuSIIpu8tvF81XHg/qraB9wBfD7JM/quqsWqOlRVh3btGpJRkqQNVq/U\n0cljcWrf3Or1tCFBsQzsn9rexzMPVe4CTgJU1feBlwB7BvQtSZqfUer1kKA4CxxIclOS3cAx4NSG\nNj8H3gKQ5LWTgX85oG9J0vyMUq9nBkVVrQJ3A6eBR4CTVXU+yb1JjkyafQB4T5IfAV8E7qxZX6eS\nJM3VWPV65tdjx+LXYyXp6nVfjx2Ld2ZLkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSp\nZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBI\nkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloGhSSpZVBIkloG\nhSSpNSgokhxOcjHJUpJ7tmjzjiQXkpxP8oX5TlOSNMQY9TpVNWvQ64CfAG8DloGzwPGqujDV5gBw\nEvjrqnoiySur6vGu34WFhVpZWZk1P0nSlCSXq2phi32j1OshRxS3AktVdamqngIeAI5uaPMe4L6q\negJg1qCSpFGMUq+HBMVe4NGp7eXJa9NuBm5O8r0kZ5Ic3qyjJCeSnEtybnV1dcDQkqQNdl2po5PH\nial9c6vXTxtwwKSyyWsbz1ftAg4AbwL2Ad9NcktV/eZp/6hqEViEtVNPA8aWJD3dalUd2mLf3Or1\ntCFHFMvA/qntfcBjm7T5WlX9vqp+ClycTESStH1GqddDguIscCDJTUl2A8eAUxvafBV4M0CSPawd\n2lwa0LckaX5Gqdczg6KqVoG7gdPAI8DJqjqf5N4kRybNTgO/SnIBeBD4YFX9avBbkyQ9a2PV65lf\njx2LX4+VpKvXfT12LN6ZLUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSS\npJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZB\nIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlqGRSSpJZBIUlq\nDQqKJIeTXEyylOSept3bk1SSQ/OboiRpqDHq9cygSHIdcB9wO3AQOJ7k4CbtbgD+HvjBrD4lSfM3\nVr0eckRxK7BUVZeq6ingAeDoJu0+CnwM+O2QgSVJczdKvR4SFHuBR6e2lyev/b8krwP2V9XXu46S\nnEhyLsm51dXVIfOTJD3drit1dPI4MbVvbvX6aQMOaJNNXqupQV8EfAK4c1ZHVbUILAIsLCzUjOaS\npGdaraqtrivMrV5PG3JEsQzsn9reBzw2tX0DcAvw7SQ/A24DTnlBW5K23Sj1ekhQnAUOJLkpyW7g\nGHDqys6qerKq9lTVjVV1I3AGOFJV5wb0LUman1Hq9cygqKpV4G7gNPAIcLKqzie5N8mRP/z9SJLm\naax6naqduVSwsLBQKysrOzK2JD1fJblcVQvbOaZ3ZkuSWgaFJKllUEiSWgaFJKllUEiSWgaFJKll\nUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiS\nWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaFJKllUEiSWgaF\nJKllUEiSWgaFJKk1KCiSHE5yMclSkns22f/+JBeSPJzkW0leM/+pSpJmGaNezwyKJNcB9wG3AweB\n40kObmj2EHCoqv4c+ArwsSFvSJI0P2PV6yFHFLcCS1V1qaqeAh4Ajk43qKoHq+ryZPMMsG9Av5Kk\n+RqlXg8Jir3Ao1Pby5PXtnIX8M3NdiQ5keRcknOrq6sDhpYkbbDrSh2dPE5M7ZtbvX7agAMmlU1e\nq00bJu8EDgFv3Gx/VS0CiwALCwub9iFJaq1W1aEt9s2tXk8bEhTLwP6p7X3AY5sM+lbgQ8Abq+p3\nA/qVJM3XKPV6yKmns8CBJDcl2Q0cA05tGPR1wGeAI1X1+IA+JUnzN0q9nhkUVbUK3A2cBh4BTlbV\n+ST3JjkyafZx4KXAl5P8R5JTW3QnSRrJWPU6VTtzqWBhYaFWVlZ2ZGxJer5KcrmqFrZzTO/MliS1\nDApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJ\nUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsug\nkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1DApJUsugkCS1BgVFksNJLiZZSnLPJvv/KMmX\nJvt/kOTGeU9UkjTbGPV6ZlAkuQ64D7gdOAgcT3JwQ7O7gCeq6s+ATwD/OPvtSJLmaax6PeSI4lZg\nqaouVdVTwAPA0Q1tjgL/Onn+FeAtSTKgb0nS/IxSr3cNGHgv8OjU9jLwhq3aVNVqkieBPwH+a7pR\nkhPAiantywPGfyHYBazu9CSeI1yLda7FOtdi3fVJzk1tL1bV4uT53Or1tCFBsVnS1B/QhsmbWQRI\ncq6qDg0Y/5rnWqxzLda5Futci3Uz1mJu9XrakFNPy8D+qe19wGNbtUmyC3g58OsBfUuS5meUej0k\nKM4CB5LclGQ3cAw4taHNKeBvJ8/fDvx7VbUJJUmau1Hq9cxTT5NzWHcDp4HrgM9W1fkk9wLnquoU\n8C/A55MssZZMxwa8ocXZTV4wXIt1rsU612Kda7Fuy7UYq17H//hLkjremS1JahkUkqTW6EHhz3+s\nG7AW709yIcnDSb6V5DU7Mc/tMGstptq9PUkluWa/GjlkLZK8Y/LZOJ/kC9s9x+0y4G/k1UkeTPLQ\n5O/kjp2Y59iSfDbJ40l+vMX+JPnkZJ0eTvL6USdUVaM9WLuY8p/AnwK7gR8BBze0+Tvg05Pnx4Av\njTmnnXoMXIs3A9dPnr/3hbwWk3Y3AN8BzgCHdnreO/i5OAA8BPzxZPuVOz3vHVyLReC9k+cHgZ/t\n9LxHWou/Al4P/HiL/XcA32TtnojbgB+MOZ+xjyj8+Y91M9eiqh6sqit3q59h7TvQ16IhnwuAjwIf\nA367nZPbZkPW4j3AfVX1BEBVPb7Nc9wuQ9aigJdNnr+cZ94jcE2oqu/Q39twFPhcrTkDvCLJq8aa\nz9hBsdnt5Hu3alNVq8CV28mvNUPWYtpdrP2P4Vo0cy2SvA7YX1Vf386J7YAhn4ubgZuTfC/JmSSH\nt21222vIWnwEeGeSZeAbwPu2Z2rPOVdbT56VIT/h8WyMcjv589Tg95nkncAh4I2jzmjntGuR5EWs\n/arlnds1oR005HOxi7XTT29i7Sjzu0luqarfjDy37TZkLY4D91fVPyX5S9buB7ilqv53/Ok9p2xr\n3Rz7iMKf/1g3ZC1I8lbgQ8CRqvrdNs1tu81aixuAW4BvJ/kZa+dgT12jF7SH/o18rap+X1U/BS6y\nFhzXmiFrcRdwEqCqvg+8BNizLbN7bhlUT+Zl7KDw5z/WzVyLyemWz7AWEtfqeWiYsRZV9WRV7amq\nG6vqRtau1xypqnObd/e8NuRv5KusfdGBJHtYOxV1aVtnuT2GrMXPgbcAJHkta0Hxy22d5XPDKeBd\nk28/3QY8WVW/GGuwUU891Xg///G8M3AtPg68FPjy5Hr+z6vqyI5NeiQD1+IFYeBanAb+JskF4H+A\nD1bVr3Zu1uMYuBYfAP45yT+wdqrlzmvxP5ZJvsjaqcY9k+sxHwZeDFBVn2bt+swdwBJwGXj3qPO5\nBtdYkjRH3pktSWoZFJKklkEhSWoZFJKklkEhSWoZFJKklkEhSWr9Hy12aEVd5E3RAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c7f9c09128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_weights(18_08_28).h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
